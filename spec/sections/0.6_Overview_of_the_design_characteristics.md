**0.6** **Overview of the design characteristics**


This clause does not form an integral part of this Recommendation | International Standard.


The coded representation specified in the syntax is designed to enable a high compression capability for a desired image
quality. With the exception of the transform bypass mode of operation for lossless coding in the High 4:4:4 Intra,
CAVLC 4:4:4 Intra, and High 4:4:4 Predictive profiles, and the I_PCM mode of operation in all profiles, the algorithm is
typically not lossless, as the exact source sample values are typically not preserved through the encoding and decoding
processes. A number of techniques may be used to achieve highly efficient compression. Encoding algorithms (not
specified in this Recommendation | International Standard) may select between inter and intra coding for block-shaped
regions of each picture. Inter coding uses motion vectors for block-based inter prediction to exploit temporal statistical
dependencies between different pictures. Intra coding uses various spatial prediction modes to exploit spatial statistical
dependencies in the source signal for a single picture. Motion vectors and intra prediction modes may be specified for a
variety of block sizes in the picture. The prediction residual is then further compressed using a transform to remove spatial
correlation inside the transform block before it is quantized, producing an irreversible process that typically discards less
important visual information while forming a close approximation to the source samples. Finally, the motion vectors or
intra prediction modes are combined with the quantized transform coefficient information and encoded using either
variable length coding or arithmetic coding.


Scalable video coding is specified in Annex G allowing the construction of bitstreams that contain sub-bitstreams that
conform to this Specification. For temporal bitstream scalability, i.e., the presence of a sub-bitstream with a smaller
temporal sampling rate than the bitstream, complete access units are removed from the bitstream when deriving the
sub-bitstream. In this case, high-level syntax and inter prediction reference pictures in the bitstream are constructed
accordingly. For spatial and quality bitstream scalability, i.e., the presence of a sub-bitstream with lower spatial resolution
or quality than the bitstream, NAL units are removed from the bitstream when deriving the sub-bitstream. In this case,
inter-layer prediction, i.e., the prediction of the higher spatial resolution or quality signal by data of the lower spatial
resolution or quality signal, is typically used for efficient coding. Otherwise, the coding algorithm as described in the
previous paragraph is used.


Multiview video coding is specified in Annex H allowing the construction of bitstreams that represent multiple views.
Similar to scalable video coding, bitstreams that represent multiple views may also contain sub-bitstreams that conform to
this Specification. For temporal bitstream scalability, i.e., the presence of a sub-bitstream with a smaller temporal sampling
rate than the bitstream, complete access units are removed from the bitstream when deriving the sub-bitstream. In this case,
high-level syntax and inter prediction reference pictures in the bitstream are constructed accordingly. For view bitstream
scalability, i.e., the presence of a sub-bitstream with fewer views than the bitstream, NAL units are removed from the
bitstream when deriving the sub-bitstream. In this case, inter-view prediction, i.e., the prediction of one view signal by
data of another view signal, is typically used for efficient coding. Otherwise, the coding algorithm as described in the
previous paragraph is used.


An extension of multiview video coding that additionally supports the inclusion of depth maps is specified in Annex I,
allowing the construction of bitstreams that represent multiple views with corresponding depth views. In a similar manner,
as with the multiview video coding specified in Annex H, bitstreams encoded as specified in Annex I may also contain
sub-bitstreams that conform to this Specification.


A multiview video coding extension with depth information is specified in Annex J. Sub-bitstreams consisting of a texture
base view conform to this Specification, sub-bitstreams consisting of multiple texture views may also conform to Annex H
of this Specification, and sub-bitstreams consisting of one or more texture views and one or more depth views may also
conform to Annex I of this Specification. Enhanced texture view coding that utilizes the associated depth views and
decoding processes for depth views are specified for this extension.





**0.6.1** **Predictive coding**


This clause does not form an integral part of this Recommendation | International Standard.


Because of the conflicting requirements of random access and highly efficient compression, two main coding types are
specified. Intra coding is done without reference to other pictures. Intra coding may provide access points to the coded
sequence where decoding can begin and continue correctly, but typically also shows only moderate compression efficiency.
Inter coding (predictive or bi-predictive) is more efficient using inter prediction of each block of sample values from some
previously decoded picture selected by the encoder. In contrast to some other video coding standards, pictures coded using
bi-predictive inter prediction may also be used as references for inter coding of other pictures.


The application of the three coding types to pictures in a sequence is flexible, and the order of the decoding process is
generally not the same as the order of the source picture capture process in the encoder or the output order from the decoder
for display. The choice is left to the encoder and will depend on the requirements of the application. The decoding order is
specified such that the decoding of pictures that use inter-picture prediction follows later in decoding order than other
pictures that are referenced in the decoding process.


**0.6.2** **Coding of progressive and interlaced video**


This clause does not form an integral part of this Recommendation | International Standard.


This Recommendation | International Standard specifies a syntax and decoding process for video that originated in either
progressive-scan or interlaced-scan form, which may be mixed together in the same sequence. The two fields of an
interlaced frame are separated in capture time while the two fields of a progressive frame share the same capture time.
Each field may be coded separately or the two fields may be coded together as a frame. Progressive frames are typically
coded as a frame. For interlaced video, the encoder can choose between frame coding and field coding. Frame coding or
field coding can be adaptively selected on a picture-by-picture basis and also on a more localized basis within a coded
frame. Frame coding is typically preferred when the video scene contains significant detail with limited motion. Field
coding typically works better when there is fast picture-to-picture motion.


**0.6.3** **Picture partitioning into macroblocks and smaller partitions**


This clause does not form an integral part of this Recommendation | International Standard.


As in previous video coding Recommendations and International Standards, a macroblock, consisting of a 16x16 block of
luma samples and two corresponding blocks of chroma samples, is used as the basic processing unit of the video decoding
process.


A macroblock can be further partitioned for inter prediction. The selection of the size of inter prediction partitions is a
result of a trade-off between the coding gain provided by using motion compensation with smaller blocks and the quantity
of data needed to represent the data for motion compensation. In this Recommendation | International Standard the inter
prediction process can form segmentations for motion representation as small as 4x4 luma samples in size, using motion
vector accuracy of one-quarter of the luma sample grid spacing displacement. The process for inter prediction of a sample
block can also involve the selection of the picture to be used as the reference picture from a number of stored previouslydecoded pictures. Motion vectors are encoded differentially with respect to predicted values formed from nearby encoded
motion vectors.


Typically, the encoder calculates appropriate motion vectors and other data elements represented in the video data stream.
This motion estimation process in the encoder and the selection of whether to use inter prediction for the representation of
each region of the video content is not specified in this Recommendation | International Standard.


**0.6.4** **Spatial redundancy reduction**


This clause does not form an integral part of this Recommendation | International Standard.


Both source pictures and prediction residuals have high spatial redundancy. This Recommendation | International Standard
is based on the use of a block-based transform method for spatial redundancy removal. After inter prediction from
previously-decoded samples in other pictures or spatial-based prediction from previously-decoded samples within the
current picture, the resulting prediction residual is split into 4x4 blocks. These are converted into the transform domain
where they are quantized. After quantization many of the transform coefficients are zero or have low amplitude and can
thus be represented with a small amount of encoded data. The processes of transformation and quantization in the encoder
are not specified in this Recommendation | International Standard.
